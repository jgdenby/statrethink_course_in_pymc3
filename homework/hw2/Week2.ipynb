{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import theano\n",
    "import random\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The weights listed below were recorded in the !Kung census, but heights were not recorded for these individuals. Provide predicted heights and 89% compatibility intervals for each of these individuals. That is, fill in the table below, using model-based predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = [45, 40, 65, 31, 53]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to load the data used to fit our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "howell = pd.read_csv('../../data/Howell1.csv', sep = ';')\n",
    "howell.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter to only adults and standardize weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "howell_adults = howell[howell.age >= 18].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "howell_adults['std_weight'] = howell_adults.weight - howell_adults.weight.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and fit model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_1:\n",
    "    # Extract data\n",
    "    weight = pm.Data('weight', howell_adults['std_weight'].values)\n",
    "    height = pm.Data('height', howell_adults['height'].values)\n",
    "    \n",
    "    # Define priors\n",
    "    alpha = pm.Normal('alpha', mu=178, sd=20)\n",
    "    beta = pm.Normal('beta', mu=0, sd=10)\n",
    "    sigma = pm.Uniform('sigma', lower=0, upper=50)\n",
    "    \n",
    "    # Define regression model\n",
    "    mu = alpha + beta * weight\n",
    "    height_hat = pm.Normal('height_hat', mu=mu, sd=sigma, observed=height)\n",
    "    \n",
    "    # Prior sampling, trace definition and posterior sampling\n",
    "    prior = pm.sample_prior_predictive()\n",
    "    posterior_1 = pm.sample(draws=1000, tune=1000)\n",
    "    posterior_pred_1 = pm.sample_posterior_predictive(posterior_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(posterior_1, alpha=.10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(posterior_1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, after fitting the model we also used draws from the posterior to predict heights for each supplied weight point. We can average the predictions for each point to get a predictive point estimate, and assess our model's fit that way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_hats = posterior_pred_1['height_hat'].mean(axis = 0)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = howell_adults['height'],\n",
    "        y = height_hats,\n",
    "        mode = 'markers'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=go.layout.XAxis(\n",
    "        title=go.layout.xaxis.Title(\n",
    "            text=\"height\",\n",
    "        )\n",
    "    ),\n",
    "    yaxis=go.layout.YAxis(\n",
    "        title=go.layout.yaxis.Title(\n",
    "            text=\"height_hat\",\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(height_hats, howell_adults['height']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 5cm - not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the HPDI for each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.hpd(posterior_pred_1['height_hat'], alpha = .11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict for our out-of-sample weight points. We need to standardize them and add them as data to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_pred_1['height_hat'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = (np.array(to_predict) - howell.weight.mean())\n",
    "weight.set_value(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_pred_1 = pm.sample_posterior_predictive(trace = posterior_1, samples = 500, model = model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(to_predict, columns = ['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['height_hat'] = posterior_pred_1['height_hat'].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.join(\n",
    "    pd.DataFrame(\n",
    "        pm.hpd(posterior_pred_1['height_hat'], alpha = .11), \n",
    "        columns = ['hpd5.5', 'hpd95.5']\n",
    "    )\n",
    ")\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Model the relationship between height (cm) and the natural logarithm of weight (log-kg): `log(weight)`. Use the entire `Howell1` data frame, all 544 rows, adults and non-adults. Use any model type from Chapter 4 that you think useful: an ordinary linear regression, a polynomial or a spline. Plot the posterior predictions against the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "howell['log_std_weight'] = np.log(howell['weight']) - np.log(howell['weight'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_2:\n",
    "    # Extract data\n",
    "    log_weight = pm.Data('log_weight', howell['log_std_weight'].values)\n",
    "    height = pm.Data('height', howell['height'].values)\n",
    "    \n",
    "    # Define priors\n",
    "    alpha = pm.Normal('alpha', mu=178, sd=20)\n",
    "    beta = pm.Normal('beta', mu=0, sd=10)\n",
    "    sigma = pm.Uniform('sigma', lower=0, upper=50)\n",
    "    \n",
    "    # Define regression model\n",
    "    mu = alpha + beta * log_weight\n",
    "    height_hat = pm.Normal('height_hat', mu=mu, sd=sigma, observed=height)\n",
    "    \n",
    "    # Prior sampling, trace definition and posterior sampling\n",
    "    prior = pm.sample_prior_predictive()\n",
    "    posterior_2 = pm.sample(draws=1000, tune=1000)\n",
    "    posterior_pred_2 = pm.sample_posterior_predictive(posterior_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_3:\n",
    "    # Extract data\n",
    "    log_weight = pm.Data('log_weight', howell['log_std_weight'].values)\n",
    "    log_weight_sq = log_weight ** 2\n",
    "    height = pm.Data('height', howell['height'].values)\n",
    "    \n",
    "    # Define priors\n",
    "    alpha = pm.Normal('alpha', mu=178, sd=20)\n",
    "    beta1= pm.Normal('beta1', mu=0, sd=10)\n",
    "    beta2 = pm.Normal('beta2', mu = 0, sd = 1)\n",
    "    sigma = pm.Uniform('sigma', lower=0, upper=50)\n",
    "    \n",
    "    # Define regression model\n",
    "    mu = alpha + beta1 * log_weight + beta2 * log_weight_sq\n",
    "    height_hat = pm.Normal('height_hat', mu=mu, sd=sigma, observed=height)\n",
    "    \n",
    "    # Prior sampling, trace definition and posterior sampling\n",
    "    prior = pm.sample_prior_predictive()\n",
    "    posterior_3 = pm.sample(draws=1000, tune=1000)\n",
    "    posterior_pred_3 = pm.sample_posterior_predictive(posterior_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "mean_lin_reg = pd.Series(posterior_pred_2['height_hat'].mean(axis = 0))\n",
    "hpdi_lin_reg = pm.hpd(posterior_pred_2['height_hat'], alpha = .11)\n",
    "mean_polynomial =  pd.Series(posterior_pred_3['height_hat'].mean(axis = 0))\n",
    "hpdi_polynomial = pm.hpd(posterior_pred_3['height_hat'], alpha = .11)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = howell['weight'],\n",
    "        y = howell['height'],\n",
    "        mode = 'markers',\n",
    "        name = 'actual',\n",
    "        opacity = .4\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = howell['weight'],\n",
    "        y = mean_lin_reg,\n",
    "        name = 'linear regression',\n",
    "        mode ='markers'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = howell['weight'],\n",
    "        y = mean_polynomial,\n",
    "        name = 'polynomial regression',\n",
    "        mode = 'markers'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=go.layout.XAxis(\n",
    "        title=go.layout.xaxis.Title(\n",
    "            text=\"weight\",\n",
    "        )\n",
    "    ),\n",
    "    yaxis=go.layout.YAxis(\n",
    "        title=go.layout.yaxis.Title(\n",
    "            text=\"height\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty similar results for the linear and polynomial regression attempts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot the prior predictive distribution for the polynomial regression model in Chapter 4. You can modify the code that plots the linear regression prior predictive distribution. 20 or 30 parabolas from the prior should suffice to show where the prior probability resides. Can you modify the prior distributions of $\\alpha$, $\\beta_1$, and $\\beta_2$ so that the prior predictions stay within the biologically reasonable outcome space? That is to say: Do not try to fit the data by hand. But do try to keep the curves consistent with what you know about height and weight, before seeing these exact data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the prior predictive distribution, we simply sample from the prior distributions for each parameter in our polynomial model, and  compute the predicted output variables using our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20\n",
    "alpha = np.random.normal(178, 20, n_samples)\n",
    "beta_1 = np.random.lognormal(0, 1, n_samples)\n",
    "beta_2 = np.random.normal(0, 1, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = howell['weight'] - howell['weight'].mean()\n",
    "weights = np.repeat(weights.to_numpy().reshape(-1,1), n_samples, axis = 1)\n",
    "height_hat = alpha + (beta_1 * weights) + (beta_2 * weights**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for curve in range(weights.shape[1]):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = howell['weight'].to_numpy(),\n",
    "            y = height_hat[:, curve],\n",
    "            mode = 'markers'\n",
    "        )\n",
    "    )\n",
    "fig.update_layout(\n",
    "    showlegend = False,\n",
    "    xaxis=go.layout.XAxis(\n",
    "        title=go.layout.xaxis.Title(\n",
    "            text=\"weight\",\n",
    "        )\n",
    "    ),\n",
    "    yaxis=go.layout.YAxis(\n",
    "        title=go.layout.yaxis.Title(\n",
    "            text=\"height\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "fig.show()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
