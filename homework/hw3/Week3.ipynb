{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foxes = pd.read_csv('../../data/foxes.csv', sep=';', header=0)\n",
    "foxes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use a model to infer the total causal influence of `area` on `weight`. Would increasing the area available to each fox make it heavier (healthier)? You might want to standardize the variables. Regardless, use prior predictive simulation to show that your modelâ€™s prior predictions stay within the possible outcome range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the prompt suggests, we start by standardizing the appropriate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['avgfood', 'groupsize', 'area', 'weight']\n",
    "foxes[features] = preprocessing.scale(foxes[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we think about setting our priors in a way that makes sense. We *don't* want to include `avgfood` as a predictor in our multiple regression, as this would induce d-separation between `weight` and `area`, distorting our ability to test the causal model of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model1:\n",
    "    \n",
    "    # data\n",
    "    weight = foxes['weight']\n",
    "    group = foxes['group']\n",
    "    avgfood = foxes['avgfood']\n",
    "    groupsize = foxes['groupsize']\n",
    "    area = foxes['area']\n",
    "    \n",
    "    # priors\n",
    "    alpha = pm.Normal('alpha', 0, .2)\n",
    "    b_area = pm.Normal('b_area', 0, .5)\n",
    "    sigma = pm.Uniform('sigma', 0, 2)\n",
    "    \n",
    "    # model\n",
    "    mu = alpha + b_area * area\n",
    "    weight_hat = pm.Normal('weight_hat', mu = mu, sigma = sigma, observed = weight)\n",
    "    \n",
    "    # sampling stuff\n",
    "    prior = pm.sample_prior_predictive(samples = 30) # a bunch of draws from the prior for each param\n",
    "    posterior1 = pm.sample(draws = 1000, tune = 1000)\n",
    "    posterior_predictive1 = pm.sample_posterior_predictive(posterior1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(posterior1, alpha=.11).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`area` doesn't appear to have any total effect on `weight` according to this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(posterior1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 30\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for draw in range(samples):\n",
    "    alpha = prior['alpha'][draw]\n",
    "    beta = prior['b_area'][draw]\n",
    "    prior_weight = alpha + beta * area\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = area,\n",
    "            y = pd.Series(prior_weight),\n",
    "            mode = 'lines'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "fig.update_layout(showlegend = False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These priors seem fine! The range of the predictions they make are well within the realm of possibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now infer the causal impact of adding food to a territory. Would this make foxes heavier? Which covariates do you need to adjust for to estimate the total causal influence of food?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want to assess the total causal impact of food, we can do a simple regression with the `avgfood` variable as a predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_2:\n",
    "    avgfood = foxes['avgfood']\n",
    "    weight = foxes['weight']\n",
    "    \n",
    "    # priors\n",
    "    alpha = pm.Normal('alpha', mu = 0, sigma = .2)\n",
    "    beta = pm.Normal('beta', mu = 0, sigma = .5)\n",
    "    sigma = pm.Uniform('sigma', 0, 2)\n",
    "    \n",
    "    # model\n",
    "    mu = alpha + beta * avgfood\n",
    "    weight_hat = pm.Normal('weight_hat', mu = mu, sigma = sigma, observed = weight)\n",
    "    \n",
    "    # sampling\n",
    "    posterior2 = pm.sample(draws = 1000, tune = 1000)\n",
    "    posterior_predictive2 = pm.sample_posterior_predictive(posterior2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(posterior2, alpha = .11).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(posterior2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting - according to this model, `avgfood` doesn't appear to have a convincing causal effect on `weight`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now infer the causal impact of group size. Which covariates do you need to adjust for? Looking at the posterior distribution of the resulting model, what do you think explains these data? That is, can you explain the estimates for all three problems? How do they go together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model3:\n",
    "    # data\n",
    "    weight = foxes['weight']\n",
    "    avgfood = foxes['avgfood']\n",
    "    groupsize = foxes['groupsize']\n",
    "    \n",
    "    # priors\n",
    "    alpha = pm.Normal('alpha', 0, .2)\n",
    "    beta = pm.Normal('beta', 0, .5, shape = 2)\n",
    "    sigma = pm.Uniform('sigma', 0, 2)\n",
    "    \n",
    "    # model\n",
    "    mu = alpha + beta[0] * avgfood + beta[1] * groupsize\n",
    "    weight_hat = pm.Normal('weight_hat', mu = mu, sigma = sigma, observed = weight)\n",
    "    \n",
    "    # sampling\n",
    "    posterior3 = pm.sample(draws = 1000, tune = 1000)\n",
    "    posterior_predictive3 = pm.sample_posterior_predictive(posterior3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model4:\n",
    "    # data\n",
    "    weight = foxes['weight']\n",
    "    avgfood = foxes['avgfood']\n",
    "    groupsize = foxes['groupsize']\n",
    "    \n",
    "    # priors\n",
    "    alpha = pm.Normal('alpha', 0, .2)\n",
    "    beta = pm.Normal('beta', 0, .5, shape = 1)\n",
    "    sigma = pm.Uniform('sigma', 0, 2)\n",
    "    \n",
    "    # model\n",
    "    mu = alpha +  beta * groupsize\n",
    "    weight_hat = pm.Normal('weight_hat', mu = mu, sigma = sigma, observed = weight)\n",
    "    \n",
    "    # sampling\n",
    "    posterior4 = pm.sample(draws = 1000, tune = 1000)\n",
    "    posterior_predictive4 = pm.sample_posterior_predictive(posterior4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(posterior3, alpha = .11).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(posterior4, alpha = .11).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
